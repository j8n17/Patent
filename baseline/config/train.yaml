data:
  path: ../data
  train: ../data/train
  category_csv: ../data/category.csv
  train_csv: ../data/train/train.csv
  save_tokenized_dataset: True

  n_fold: 5
  test_fold: 0
  split_seed: 42
  debug: false

  upsampling: True

model:
  # name: kopatelectra
  # name: koelectra
  name: kobart
  num_labels: 564

train:
  restart_path: ''
  checkpoint_path: ''

  hierarchical: 
    SSno: True
    Sno: False
    Mno: False
    Lno: False
    LLno: False

  seed: 42
  deterministic: False
  gpu_id: "0"
  
  optim: adamw_torch
  
  fine_tune: 
    enable: True
    n_layer: 2

  use_step: True
  epochs: 3
  batch_size: 16
  learning_rate: 5e-5
  warmup_steps: 0
  lr_scheduler_type: 'constant' # 'linear'
  # early_stop_patience: 5

  output_dir: './results'
  save_total_limit: 3
  report_to: ['tensorboard']

  loss:
    name: FocalLoss
    params:
      gamma: 2 # gamma가 커질수록 어려운 데이터에 더 집중함.
