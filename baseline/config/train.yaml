data:
  path: ../data
  train: ../data/train
  category_csv: ../data/category.csv
  train_csv: ../data/train/train.csv
  save_tokenized_dataset: True

  n_fold: 5
  valid_fold: 0
  split_seed: 42
  debug: false

  upsampling: True

model:
  # name: kopatelectra
  # name: koelectra
  name: kobart
  num_labels: 564

train:
  restart_path: ''
  checkpoint_path: ''

  extra_hierarchy: 
    Sno: False
    Mno: False
    Lno: False
    LLno: True

  gpu_id: "0"
  
  fine_tune: 
    enable: True
    n_layer: 1

  epochs: 10
  batch_size: 16
  grad_accumulation: False
  
  optim: adamw_torch

  find_optimal_lr: False
  learning_rate: 5e-5
  lr_scheduler_type: 'constant' # 'linear'
  warmup_steps: 0
  # early_stop_patience: 5

  valid:
    eval_first: False
    compute_metrics: False
    eval_accumulation_steps: 0 # 9

  output_dir: './results'
  save_total_limit: 10
  report_to: ['tensorboard']

  loss:
    name: FocalLoss
    params:
      gamma: 2 # gamma가 커질수록 어려운 데이터에 더 집중함.

setting:
  seed: 42
  deterministic: False
